{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pymongo\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define database and collection\n",
    "db = client.mars_db\n",
    "collection = db.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 89.0.4389\n",
      "[WDM] - Get LATEST driver version for 89.0.4389\n",
      "[WDM] - Driver [/Users/melissa/.wdm/drivers/chromedriver/mac64/89.0.4389.23/chromedriver] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "# This is not the given website, but I get returns, so I'm working with it for now\n",
    "news_url = (\"https://redplanetscience.com/#\")\n",
    "browser.visit(news_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML Object\n",
    "html = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mars 2020 Stands on Its Own Six Wheels\n",
      "In time-lapse video, taken at JPL, captures the first time NASA's Mars 2020 rover carries its full weight on its legs and wheels.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the latest element that contains news title and news_paragraph\n",
    "title = soup.find('div', class_='content_title').text\n",
    "article_teaser = soup.find('div', class_='article_teaser_body').text\n",
    "\n",
    "# Display scrapped data \n",
    "print(title)\n",
    "print(article_teaser)\n",
    "\n",
    "# I think my issue was using find_all and .text together incorrectly and also not having the splinter set up.\n",
    "# I'm still unsure about how it all relates and why it won't work without the other, but at least I can start moving forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://spaceimages-mars.com/image/featured/mars2.jpg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JPL Mars image\n",
    "\n",
    "jpl_url = (\"https://spaceimages-mars.com/\")\n",
    "browser.visit(jpl_url)\n",
    "\n",
    "# Set up new instance of HTML object\n",
    "html = browser.html\n",
    "\n",
    "# Parse the HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "response = soup.find('a', class_='showimg')\n",
    "\n",
    "# print(response)\n",
    "\n",
    "href = response['href']\n",
    "\n",
    "img_url = jpl_url + href\n",
    "\n",
    "img_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mars Facts\n",
    "https://galaxyfacts-mars.com/\n",
    "\n",
    "\n",
    "Visit the Mars Facts webpage here and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "\n",
    "\n",
    "Use Pandas to convert the data to a HTML table string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try some table reading\n",
    "# Look into weird character issues\n",
    "facts_url = 'https://galaxyfacts-mars.com/'\n",
    "\n",
    "tables = pd.read_html(facts_url)\n",
    "tables\n",
    "\n",
    "mars_facts = tables[0]\n",
    "mars_facts\n",
    "\n",
    "mars_html = mars_facts.to_html('mars_facts.html')\n",
    "mars_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mars Hemispheres\n",
    "\n",
    "\n",
    "Visit the astrogeology site here to obtain high resolution images for each of Mars's hemispheres.\n",
    "\n",
    "\n",
    "You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "\n",
    "\n",
    "Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys img_url and title.\n",
    "\n",
    "\n",
    "Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"item\">\n",
       " <a class=\"itemLink product-item\" href=\"cerberus.html\"><img alt=\"Cerberus Hemisphere Enhanced thumbnail\" class=\"thumb\" src=\"images/39d3266553462198bd2fbc4d18fbed17_cerberus_enhanced.tif_thumb.png\"/></a>\n",
       " <div class=\"description\">\n",
       " <a class=\"itemLink product-item\" href=\"cerberus.html\">\n",
       " <h3>Cerberus Hemisphere Enhanced</h3>\n",
       " </a>\n",
       " <span class=\"subtitle\" style=\"float:left\">image/tiff 21 MB</span><span class=\"pubDate\" style=\"float:right\"></span><br/>\n",
       " <p>Mosaic of the Cerberus hemisphere of Mars projected into point perspective, a view similar to that which one would see from a spacecraft. This mosaic is composed of 104 Viking Orbiter images acquired…</p>\n",
       " </div>\n",
       " <!-- end description -->\n",
       " </div>,\n",
       " <div class=\"item\">\n",
       " <a class=\"itemLink product-item\" href=\"schiaparelli.html\"><img alt=\"Schiaparelli Hemisphere Enhanced thumbnail\" class=\"thumb\" src=\"images/08eac6e22c07fb1fe72223a79252de20_schiaparelli_enhanced.tif_thumb.png\"/></a>\n",
       " <div class=\"description\">\n",
       " <a class=\"itemLink product-item\" href=\"schiaparelli.html\">\n",
       " <h3>Schiaparelli Hemisphere Enhanced</h3>\n",
       " </a>\n",
       " <span class=\"subtitle\" style=\"float:left\">image/tiff 35 MB</span><span class=\"pubDate\" style=\"float:right\"></span><br/>\n",
       " <p>Mosaic of the Schiaparelli hemisphere of Mars projected into point perspective, a view similar to that which one would see from a spacecraft. The images were acquired in 1980 during early northern…</p>\n",
       " </div>\n",
       " <!-- end description -->\n",
       " </div>,\n",
       " <div class=\"item\">\n",
       " <a class=\"itemLink product-item\" href=\"syrtis.html\"><img alt=\"Syrtis Major Hemisphere Enhanced thumbnail\" class=\"thumb\" src=\"images/55a0a1e2796313fdeafb17c35925e8ac_syrtis_major_enhanced.tif_thumb.png\"/></a>\n",
       " <div class=\"description\">\n",
       " <a class=\"itemLink product-item\" href=\"syrtis.html\">\n",
       " <h3>Syrtis Major Hemisphere Enhanced</h3>\n",
       " </a>\n",
       " <span class=\"subtitle\" style=\"float:left\">image/tiff 25 MB</span><span class=\"pubDate\" style=\"float:right\"></span><br/>\n",
       " <p>Mosaic of the Syrtis Major hemisphere of Mars projected into point perspective, a view similar to that which one would see from a spacecraft. This mosaic is composed of about 100 red and violet…</p>\n",
       " </div>\n",
       " <!-- end description -->\n",
       " </div>,\n",
       " <div class=\"item\">\n",
       " <a class=\"itemLink product-item\" href=\"valles.html\"><img alt=\"Valles Marineris Hemisphere Enhanced thumbnail\" class=\"thumb\" src=\"images/4e59980c1c57f89c680c0e1ccabbeff1_valles_marineris_enhanced.tif_thumb.png\"/></a>\n",
       " <div class=\"description\">\n",
       " <a class=\"itemLink product-item\" href=\"valles.html\">\n",
       " <h3>Valles Marineris Hemisphere Enhanced</h3>\n",
       " </a>\n",
       " <span class=\"subtitle\" style=\"float:left\">image/tiff 27 MB</span><span class=\"pubDate\" style=\"float:right\"></span><br/>\n",
       " <p>Mosaic of the Valles Marineris hemisphere of Mars projected into point perspective, a view similar to that which one would see from a spacecraft. The distance is 2500 kilometers from the surface of…</p>\n",
       " </div>\n",
       " <!-- end description -->\n",
       " </div>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect the image urls for the given website\n",
    "# Ok, this works to pull one. How to get the other three?\n",
    "hemisphere_url = 'https://marshemispheres.com/'\n",
    "browser.visit(hemisphere_url)\n",
    "\n",
    "# Do not forget new instance!!!!\n",
    "html = browser.html\n",
    "\n",
    "# Parse the HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "responses = soup.find_all('div', class_='item')\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n",
      "-----------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all pages\n",
    "for x in range(5):\n",
    "    # HTML object\n",
    "    html = browser.html\n",
    "    # Parse HTML with Beautiful Soup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # Retrieve all elements that contain image info\n",
    "    images = soup.find_all('img', class_='thumb')\n",
    "\n",
    "    # Iterate through each book\n",
    "    for image in images:\n",
    "        # Use Beautiful Soup's find() method to navigate and retrieve attributes\n",
    "        src = image.find('src')\n",
    "#         link = h3.find('a')\n",
    "#         href = link['href']\n",
    "#         title = link['title']\n",
    "        print('-----------')\n",
    "        print(src)\n",
    "#         print('http://books.toscrape.com/' + href)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Cerberus Hemisphere Enhanced',\n",
       "  'img_url': 'https://marshemispheres.com/images/f5e372a36edfa389625da6d0cc25d905_cerberus_enhanced.tif_full.jpg'},\n",
       " {'title': 'Schiaparelli Hemisphere Enhanced',\n",
       "  'img_url': 'https://marshemispheres.com/images/3778f7b43bbbc89d6e3cfabb3613ba93_schiaparelli_enhanced.tif_full.jpg'},\n",
       " {'title': 'Syrtis Major Hemisphere Enhanced',\n",
       "  'img_url': 'https://marshemispheres.com/images/555e6403a6ddd7ba16ddb0e471cadcf7_syrtis_major_enhanced.tif_full.jpg'},\n",
       " {'title': 'Valles Marineris Hemisphere Enhanced',\n",
       "  'img_url': 'https://marshemispheres.com/images/b3c7c6c9138f57b4756be9b9c43e3a48_valles_marineris_enhanced.tif_full.jpg'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect the image urls for the given website\n",
    "# Why does it work with h3 and not h2?\n",
    "hemisphere_url = 'https://marshemispheres.com/'\n",
    "browser.visit(hemisphere_url)\n",
    "\n",
    "# Do not forget new instance!!!!\n",
    "html = browser.html\n",
    "\n",
    "# Parse the HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Retreive all items that contain mars hemispheres information\n",
    "images = soup.find_all('div', class_='item')\n",
    "\n",
    "# Create empty list for hemisphere urls \n",
    "image_urls = []\n",
    "\n",
    "# Store the main_ul \n",
    "main_url = 'https://marshemispheres.com/'\n",
    "\n",
    "# Loop through the items previously stored\n",
    "for image in images: \n",
    "    # Store title\n",
    "#     title = image.find('h3').text\n",
    "    \n",
    "    # Store link that leads to full image website\n",
    "    partial_img_url = image.find('a', class_='itemLink product-item')['href']\n",
    "    \n",
    "    # Visit the link that contains the full image website \n",
    "    browser.visit(main_url + partial_img_url)\n",
    "    \n",
    "    # HTML Object of individual hemisphere information website \n",
    "    partial_img_html = browser.html\n",
    "    \n",
    "    # Parse HTML with Beautiful Soup for every individual hemisphere information website \n",
    "    soup = BeautifulSoup(partial_img_html, 'html.parser')\n",
    "    \n",
    "    # Retrieve full image source \n",
    "    img_url = main_url + soup.find('img', class_='wide-image')['src']\n",
    "    \n",
    "    title = soup.find('h2', class_='title').text\n",
    "    \n",
    "    # Append the retreived information into a list of dictionaries \n",
    "    image_urls.append({\"title\" : title, \"img_url\" : img_url})\n",
    "    \n",
    "\n",
    "# Display hemisphere_image_urls\n",
    "image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
