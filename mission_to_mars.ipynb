{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pymongo\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define database and collection\n",
    "db = client.mars_db\n",
    "collection = db.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 89.0.4389\n",
      "[WDM] - Get LATEST driver version for 89.0.4389\n",
      "[WDM] - Driver [/Users/melissa/.wdm/drivers/chromedriver/mac64/89.0.4389.23/chromedriver] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "# This is not the given website, but I get returns, so I'm working with it for now\n",
    "news_url = (\"https://redplanetscience.com/#\")\n",
    "browser.visit(news_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML Object\n",
    "html = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA to Broadcast Mars 2020 Perseverance Launch, Prelaunch Activities\n",
      "Starting July 27, news activities will cover everything from mission engineering and science to returning samples from Mars to, of course, the launch itself.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the latest element that contains news title and news_paragraph\n",
    "title = soup.find('div', class_='content_title').text\n",
    "article_teaser = soup.find('div', class_='article_teaser_body').text\n",
    "\n",
    "# Display scrapped data \n",
    "print(title)\n",
    "print(article_teaser)\n",
    "\n",
    "# I think my issue was using find_all and .text together incorrectly and also not having the splinter set up.\n",
    "# I'm still unsure about how it all relates and why it won't work without the other, but at least I can start moving forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JPL Mars image\n",
    "\n",
    "jpl_url = (\"https://spaceimages-mars.com/\")\n",
    "browser.visit(jpl_url)\n",
    "\n",
    "# Set up new instance of HTML object\n",
    "html = browser.html\n",
    "\n",
    "# Parse the HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Gather featured_image_url\n",
    "# img-card-top\n",
    "\n",
    "img_url = soup.find('img', class_='headerimage fade in')\n",
    "\n",
    "\n",
    "print(img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://spaceimages-mars.com/image/featured/mars1.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve page with the requests module\n",
    "response = requests.get(jpl_url)\n",
    "# Create BeautifulSoup object; parse with 'lxml'\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# soup\n",
    "\n",
    "\n",
    "# pull images from website\n",
    "images = soup.find_all('a', class_=\"fancybox\")\n",
    "#print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-89e2d1089261>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpic_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfeatured_image_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://www.jpl.nasa.gov'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mfeatured_image_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pic' is not defined"
     ]
    }
   ],
   "source": [
    "# pull image link\n",
    "pic_src = []\n",
    "for image in images:\n",
    "    pic = image['data-fancybox-href']\n",
    "    pic_src.append(pic)\n",
    "\n",
    "featured_image_url = 'https://www.jpl.nasa.gov' + pic\n",
    "featured_image_url\n",
    "\n",
    "\n",
    "\n",
    "# <a target=\"_blank\" class=\"showimg fancybox-thumbs\" href=\"image/featured/mars3.jpg\"> \n",
    "# <button class=\"btn btn-outline-light\"> FULL IMAGE</button></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the results, then determine element that contains sought info\n",
    "# results are returned as an iterable list\n",
    "# results = soup.find_all('img', class_='headerimage')\n",
    "\n",
    "# Loop through returned results\n",
    "for result in images:\n",
    "    # Error handling\n",
    "    try:\n",
    "        # Identify and return title of listing\n",
    "#         title = result.find('a', class_='title').text\n",
    "        # Identify and return link to listing\n",
    "        link = result.a['href']\n",
    "\n",
    "        # Run only if title, price, and link are available\n",
    "        if (link):\n",
    "            print(link)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
